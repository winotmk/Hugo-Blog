<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=14127&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 | ExampleSite</title>
<meta name=keywords content="AI,阿里云,stable diffusion,linux"><meta name=description content="创建阿里云PAI DSW实例跑kohya
镜像我这里选：

dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04
我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作
安装kohya_ss
kohya_ss仓库地址：
https://github.com/bmaltais/kohya_ss
kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora
在workspace根目录直接：
git clone https://github.com/bmaltais/kohya_ss.git

很快就能完成，接着依次执行
cd ./kohya_ss
apt update -y && apt install -y python3-tk
chmod +x ./setup.sh
./setup.sh
虽然镜像里带py310，但是似乎还是要装一下python3-tk
之后安装脚本会自动完成，我大概花了5分钟

然后运行启动webui
HF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless

点击这个本地的IP即能点开webui了
HF_ENDPOINT=https://hf-mirror.com是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章：
https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/
kohya_ss的Dreambooth训练参数
source model

我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了
floders
这个tag里比较简单，没什么好说的
Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样
parameters

basic
和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧
samples
这里能填关键词和每多少轮出个预览图，玩玩用
都准备好了就可以点 start training，但webui不会有任何提示..要看之前启webui的终端
这样就是开始训练了：

不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
The following directories listed in your path were found to be non-existent: {PosixPath('//license-pai.cn-shanghai.data.aliyun.com'), PosixPath('http')}
The following directories listed in your path were found to be non-existent: {PosixPath('dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service'), PosixPath('aigc-torch113-cu117-ubuntu22.04-v0.2.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('8088/dsw-301739'), PosixPath('//127.0.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}
The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//dsw-cn-shanghai.data.aliyun.com')}
The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('/home/pai/bin/python')}
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}
CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!                     If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes
  warn(msg)
CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...
libcusparse.so.11: cannot open shared object file: No such file or directory
CUDA SETUP: Something unexpected happened. Please compile from source:
git clone https://github.com/TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=118 make cuda11x_nomatmul
python setup.py install
Traceback (most recent call last):
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 110, in _get_module_details
    __import__(pkg_name)
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py&#34;, line 6, in <module>
    from . import cuda_setup, utils, research
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py&#34;, line 1, in <module>
    from . import nn
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py&#34;, line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py&#34;, line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py&#34;, line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py&#34;, line 20, in <module>
    raise RuntimeError('''
以及如果遇到类似："><meta name=author content="Me"><link rel=canonical href=http://localhost:14127/posts/240110_sd%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%91%E4%B8%8A%E8%AE%AD%E7%BB%83/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.9de45e225101e4f99701d2b68fc6b8a1ef6027928be6391fa15bf7f56326c909.css integrity="sha256-neReIlEB5PmXAdK2j8a4oe9gJ5KL5jkfoVv39WMmyQk=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:14127/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:14127/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:14127/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:14127/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:14127/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:14127/posts/240110_sd%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%91%E4%B8%8A%E8%AE%AD%E7%BB%83/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:14127/posts/240110_sd%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%91%E4%B8%8A%E8%AE%AD%E7%BB%83/"><meta property="og:site_name" content="ExampleSite"><meta property="og:title" content="StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本"><meta property="og:description" content="创建阿里云PAI DSW实例跑kohya 镜像我这里选： dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04 我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作
安装kohya_ss kohya_ss仓库地址： https://github.com/bmaltais/kohya_ss kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora 在workspace根目录直接：
git clone https://github.com/bmaltais/kohya_ss.git 很快就能完成，接着依次执行
cd ./kohya_ssapt update -y && apt install -y python3-tkchmod +x ./setup.sh./setup.sh 虽然镜像里带py310，但是似乎还是要装一下python3-tk 之后安装脚本会自动完成，我大概花了5分钟 然后运行启动webui
HF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless 点击这个本地的IP即能点开webui了 HF_ENDPOINT=https://hf-mirror.com是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章： https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/
kohya_ss的Dreambooth训练参数 source model 我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了
floders 这个tag里比较简单，没什么好说的 Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样
parameters basic 和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧
samples 这里能填关键词和每多少轮出个预览图，玩玩用 都准备好了就可以点 start training，但webui不会有任何提示..要看之前启webui的终端 这样就是开始训练了： 不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...warn(msg)The following directories listed in your path were found to be non-existent: {PosixPath('//license-pai.cn-shanghai.data.aliyun.com'), PosixPath('http')}The following directories listed in your path were found to be non-existent: {PosixPath('dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service'), PosixPath('aigc-torch113-cu117-ubuntu22.04-v0.2.1')}The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('8088/dsw-301739'), PosixPath('//127.0.0.1')}The following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//dsw-cn-shanghai.data.aliyun.com')}The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}The following directories listed in your path were found to be non-existent: {PosixPath('/home/pai/bin/python')}CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU! If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbyteswarn(msg)CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...libcusparse.so.11: cannot open shared object file: No such file or directoryCUDA SETUP: Something unexpected happened. Please compile from source:git clone https://github.com/TimDettmers/bitsandbytes.gitcd bitsandbytesCUDA_VERSION=118 make cuda11x_nomatmulpython setup.py installTraceback (most recent call last):File &#34;/usr/lib/python3.10/runpy.py&#34;, line 187, in _run_module_as_mainmod_name, mod_spec, code = _get_module_details(mod_name, _Error)File &#34;/usr/lib/python3.10/runpy.py&#34;, line 146, in _get_module_detailsreturn _get_module_details(pkg_main_name, error)File &#34;/usr/lib/python3.10/runpy.py&#34;, line 110, in _get_module_details__import__(pkg_name)File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py&#34;, line 6, in <module>from . import cuda_setup, utils, researchFile &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py&#34;, line 1, in <module>from . import nnFile &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py&#34;, line 1, in <module>from .modules import LinearFP8Mixed, LinearFP8GlobalFile &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py&#34;, line 8, in <module>from bitsandbytes.optim import GlobalOptimManagerFile &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py&#34;, line 6, in <module>from bitsandbytes.cextension import COMPILED_WITH_CUDAFile &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py&#34;, line 20, in <module>raise RuntimeError(''' 以及如果遇到类似："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-11T00:00:00+00:00"><meta property="article:modified_time" content="2024-01-11T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="阿里云"><meta property="article:tag" content="Stable Diffusion"><meta property="article:tag" content="Linux"><meta property="og:image" content="http://localhost:14127/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:14127/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本"><meta name=twitter:description content="创建阿里云PAI DSW实例跑kohya
镜像我这里选：

dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04
我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作
安装kohya_ss
kohya_ss仓库地址：
https://github.com/bmaltais/kohya_ss
kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora
在workspace根目录直接：
git clone https://github.com/bmaltais/kohya_ss.git

很快就能完成，接着依次执行
cd ./kohya_ss
apt update -y && apt install -y python3-tk
chmod +x ./setup.sh
./setup.sh
虽然镜像里带py310，但是似乎还是要装一下python3-tk
之后安装脚本会自动完成，我大概花了5分钟

然后运行启动webui
HF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless

点击这个本地的IP即能点开webui了
HF_ENDPOINT=https://hf-mirror.com是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章：
https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/
kohya_ss的Dreambooth训练参数
source model

我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了
floders
这个tag里比较简单，没什么好说的
Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样
parameters

basic
和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧
samples
这里能填关键词和每多少轮出个预览图，玩玩用
都准备好了就可以点 start training，但webui不会有任何提示..要看之前启webui的终端
这样就是开始训练了：

不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
The following directories listed in your path were found to be non-existent: {PosixPath('//license-pai.cn-shanghai.data.aliyun.com'), PosixPath('http')}
The following directories listed in your path were found to be non-existent: {PosixPath('dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service'), PosixPath('aigc-torch113-cu117-ubuntu22.04-v0.2.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('8088/dsw-301739'), PosixPath('//127.0.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}
The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//dsw-cn-shanghai.data.aliyun.com')}
The following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}
The following directories listed in your path were found to be non-existent: {PosixPath('/home/pai/bin/python')}
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}
CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!                     If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes
  warn(msg)
CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...
libcusparse.so.11: cannot open shared object file: No such file or directory
CUDA SETUP: Something unexpected happened. Please compile from source:
git clone https://github.com/TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=118 make cuda11x_nomatmul
python setup.py install
Traceback (most recent call last):
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 110, in _get_module_details
    __import__(pkg_name)
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py&#34;, line 6, in <module>
    from . import cuda_setup, utils, research
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py&#34;, line 1, in <module>
    from . import nn
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py&#34;, line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py&#34;, line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py&#34;, line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py&#34;, line 20, in <module>
    raise RuntimeError('''
以及如果遇到类似："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:14127/posts/"},{"@type":"ListItem","position":2,"name":"StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本","item":"http://localhost:14127/posts/240110_sd%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%91%E4%B8%8A%E8%AE%AD%E7%BB%83/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本","name":"StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本","description":"创建阿里云PAI DSW实例跑kohya 镜像我这里选： dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04 我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作\n安装kohya_ss kohya_ss仓库地址： https://github.com/bmaltais/kohya_ss kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora 在workspace根目录直接：\ngit clone https://github.com/bmaltais/kohya_ss.git 很快就能完成，接着依次执行\ncd ./kohya_ss\rapt update -y \u0026amp;\u0026amp; apt install -y python3-tk\rchmod +x ./setup.sh\r./setup.sh 虽然镜像里带py310，但是似乎还是要装一下python3-tk 之后安装脚本会自动完成，我大概花了5分钟 然后运行启动webui\nHF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless 点击这个本地的IP即能点开webui了 HF_ENDPOINT=https://hf-mirror.com是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章： https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/\nkohya_ss的Dreambooth训练参数 source model 我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了\nfloders 这个tag里比较简单，没什么好说的 Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样\nparameters basic 和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧\nsamples 这里能填关键词和每多少轮出个预览图，玩玩用 都准备好了就可以点 start training，但webui不会有任何提示..要看之前启webui的终端 这样就是开始训练了： 不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：\nThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;/usr/local/nvidia/lib64\u0026#39;), PosixPath(\u0026#39;/usr/local/nvidia/lib\u0026#39;)}\r/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain [\u0026#39;libcudart.so\u0026#39;, \u0026#39;libcudart.so.11.0\u0026#39;, \u0026#39;libcudart.so.12.0\u0026#39;] as expected! Searching further paths...\rwarn(msg)\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;//license-pai.cn-shanghai.data.aliyun.com\u0026#39;), PosixPath(\u0026#39;http\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service\u0026#39;), PosixPath(\u0026#39;aigc-torch113-cu117-ubuntu22.04-v0.2.1\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;http\u0026#39;), PosixPath(\u0026#39;8088/dsw-301739\u0026#39;), PosixPath(\u0026#39;//127.0.0.1\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;Asia/Shanghai\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;tcp\u0026#39;), PosixPath(\u0026#39;443\u0026#39;), PosixPath(\u0026#39;//10.192.0.1\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;https\u0026#39;), PosixPath(\u0026#39;//dsw-cn-shanghai.data.aliyun.com\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;tcp\u0026#39;), PosixPath(\u0026#39;443\u0026#39;), PosixPath(\u0026#39;//10.192.0.1\u0026#39;)}\rThe following directories listed in your path were found to be non-existent: {PosixPath(\u0026#39;/home/pai/bin/python\u0026#39;)}\rCUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\rDEBUG: Possible options found for libcudart.so: {PosixPath(\u0026#39;/usr/local/cuda/lib64/libcudart.so.11.0\u0026#39;)}\rCUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.\rCUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\r/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability \u0026lt; 7.5 detected! Only slow 8-bit matmul is supported for your GPU! If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes\rwarn(msg)\rCUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\rlibcusparse.so.11: cannot open shared object file: No such file or directory\rCUDA SETUP: Something unexpected happened. Please compile from source:\rgit clone https://github.com/TimDettmers/bitsandbytes.git\rcd bitsandbytes\rCUDA_VERSION=118 make cuda11x_nomatmul\rpython setup.py install\rTraceback (most recent call last):\rFile \u0026#34;/usr/lib/python3.10/runpy.py\u0026#34;, line 187, in _run_module_as_main\rmod_name, mod_spec, code = _get_module_details(mod_name, _Error)\rFile \u0026#34;/usr/lib/python3.10/runpy.py\u0026#34;, line 146, in _get_module_details\rreturn _get_module_details(pkg_main_name, error)\rFile \u0026#34;/usr/lib/python3.10/runpy.py\u0026#34;, line 110, in _get_module_details\r__import__(pkg_name)\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py\u0026#34;, line 6, in \u0026lt;module\u0026gt;\rfrom . import cuda_setup, utils, research\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py\u0026#34;, line 1, in \u0026lt;module\u0026gt;\rfrom . import nn\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py\u0026#34;, line 1, in \u0026lt;module\u0026gt;\rfrom .modules import LinearFP8Mixed, LinearFP8Global\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py\u0026#34;, line 8, in \u0026lt;module\u0026gt;\rfrom bitsandbytes.optim import GlobalOptimManager\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py\u0026#34;, line 6, in \u0026lt;module\u0026gt;\rfrom bitsandbytes.cextension import COMPILED_WITH_CUDA\rFile \u0026#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\u0026#34;, line 20, in \u0026lt;module\u0026gt;\rraise RuntimeError(\u0026#39;\u0026#39;\u0026#39; 以及如果遇到类似：\n","keywords":["AI","阿里云","stable diffusion","linux"],"articleBody":"创建阿里云PAI DSW实例跑kohya 镜像我这里选： dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04 我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作\n安装kohya_ss kohya_ss仓库地址： https://github.com/bmaltais/kohya_ss kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora 在workspace根目录直接：\ngit clone https://github.com/bmaltais/kohya_ss.git 很快就能完成，接着依次执行\ncd ./kohya_ss\rapt update -y \u0026\u0026 apt install -y python3-tk\rchmod +x ./setup.sh\r./setup.sh 虽然镜像里带py310，但是似乎还是要装一下python3-tk 之后安装脚本会自动完成，我大概花了5分钟 然后运行启动webui\nHF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless 点击这个本地的IP即能点开webui了 HF_ENDPOINT=https://hf-mirror.com是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章： https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/\nkohya_ss的Dreambooth训练参数 source model 我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了\nfloders 这个tag里比较简单，没什么好说的 Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样\nparameters basic 和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧\nsamples 这里能填关键词和每多少轮出个预览图，玩玩用 都准备好了就可以点 start training，但webui不会有任何提示..要看之前启webui的终端 这样就是开始训练了： 不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：\nThe following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\r/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\rwarn(msg)\rThe following directories listed in your path were found to be non-existent: {PosixPath('//license-pai.cn-shanghai.data.aliyun.com'), PosixPath('http')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service'), PosixPath('aigc-torch113-cu117-ubuntu22.04-v0.2.1')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('8088/dsw-301739'), PosixPath('//127.0.0.1')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('Asia/Shanghai')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//dsw-cn-shanghai.data.aliyun.com')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('tcp'), PosixPath('443'), PosixPath('//10.192.0.1')}\rThe following directories listed in your path were found to be non-existent: {PosixPath('/home/pai/bin/python')}\rCUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\rDEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}\rCUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.\rCUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\r/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability \u003c 7.5 detected! Only slow 8-bit matmul is supported for your GPU! If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes\rwarn(msg)\rCUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\rlibcusparse.so.11: cannot open shared object file: No such file or directory\rCUDA SETUP: Something unexpected happened. Please compile from source:\rgit clone https://github.com/TimDettmers/bitsandbytes.git\rcd bitsandbytes\rCUDA_VERSION=118 make cuda11x_nomatmul\rpython setup.py install\rTraceback (most recent call last):\rFile \"/usr/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\rmod_name, mod_spec, code = _get_module_details(mod_name, _Error)\rFile \"/usr/lib/python3.10/runpy.py\", line 146, in _get_module_details\rreturn _get_module_details(pkg_main_name, error)\rFile \"/usr/lib/python3.10/runpy.py\", line 110, in _get_module_details\r__import__(pkg_name)\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py\", line 6, in from . import cuda_setup, utils, research\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py\", line 1, in from . import nn\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py\", line 1, in from .modules import LinearFP8Mixed, LinearFP8Global\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py\", line 8, in from bitsandbytes.optim import GlobalOptimManager\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py\", line 6, in from bitsandbytes.cextension import COMPILED_WITH_CUDA\rFile \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 20, in raise RuntimeError(''' 以及如果遇到类似：\nCould not load dynamic library 'libcudart.so.11.0' 重新装适合的CUDA版本即可解决，如果要装CUDA：\nCUDA相关 安装CUDA指定版本 遇到过cuda版本不匹配的问题，记一下配置过程 cuda下载：https://developer.nvidia.com/cuda-downloads 但是有时候需要特定版本：https://developer.nvidia.com/cuda-toolkit-archive 以11.8为例，系统是ubuntu22.04，所以这样选： 下载安装cuda：\ncd /mnt/workspace\rwget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\rsudo sh cuda_11.8.0_520.61.05_linux.run 大约3-4GB左右，运行后需要等一会，会弹出交互界面 这里去掉安装驱动，因为我们已经有驱动了只是想要不同版本的cuda，然后选安装\nps如果遇到装了多份驱动需要卸一个的情况： https://www.jianshu.com/p/54928967e417\n装好以后他会提示： 需要往 LD_LIBRARY_PATH 和 PATH 里添加两条环境变量\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64\rexport PATH=$PATH:/usr/local/cuda-11.8/bin 之后我使用\npython -m bitsandbytes 如果没有报错应该就是好用的\nps如果是windows上的wsl：\nexport LD_LIBRARY_PATH=/usr/lib/wsl/lib/ 切换cuda版本 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.7\rexport BNB_CUDA_VERSION=117 改环境变量可以手动切换版本（当然得已经装了)\n查看cuda版本 nvidia-smi 或者可以： 参考：https://blog.csdn.net/Kefenggewu_/article/details/117675079 默认cuda会装在/usr/local,所以查看安装版本可以这样：\nls -l /usr/local | grep cuda 或者据说可以nvcc -V # (V大写)\n本节另外的参考：https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n链接 kohya_ss: https://github.com/bmaltais/kohya_ss 一个封装好的kohya-docker的镜像 https://github.com/ashleykleynhans/kohya-docker\ndreambooth相关介绍： https://huggingface.co/docs/diffusers/training/dreambooth https://github.com/google/dreambooth\n","wordCount":"479","inLanguage":"en","image":"http://localhost:14127/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-01-11T00:00:00Z","dateModified":"2024-01-11T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:14127/posts/240110_sd%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%91%E4%B8%8A%E8%AE%AD%E7%BB%83/"},"publisher":{"@type":"Organization","name":"ExampleSite","logo":{"@type":"ImageObject","url":"http://localhost:14127/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:14127/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:14127/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:14127/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:14127/tags/ title=tags><span>tags</span></a></li><li><a href=https://example.org title=example.org><span>example.org</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:14127/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:14127/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本</h1><div class=post-meta><span title='2024-01-11 00:00:00 +0000 UTC'>2024-01-11</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;479 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/240110_SD%e5%a4%a7%e6%a8%a1%e5%9e%8b%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h2 id=创建阿里云pai-dsw实例跑kohya>创建阿里云PAI DSW实例跑kohya<a hidden class=anchor aria-hidden=true href=#创建阿里云pai-dsw实例跑kohya>#</a></h2><p>镜像我这里选：
<img loading=lazy src=images/20240110174810.png>
<code>dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.10.0-pytorch2.1.0tensorflow2.14.0-gpu-py310-cu118-ubuntu22.04</code>
我这里用默认的镜像，实测截至2024.01.10时，直接拉kohya的github可以直接用，不需要改动cuda之类的操作</p><h3 id=安装kohya_ss>安装kohya_ss<a hidden class=anchor aria-hidden=true href=#安装kohya_ss>#</a></h3><p>kohya_ss仓库地址：
<a href=https://github.com/bmaltais/kohya_ss>https://github.com/bmaltais/kohya_ss</a>
kohya_ss是个webui训练器，SD web_ui里也有对应的Dreambooth训练插件移植，如果只拿来训练不需要跑完整的sd webui服务，只需要kohya就可以了,kohay也可以练lora
在workspace根目录直接：</p><pre tabindex=0><code>git clone https://github.com/bmaltais/kohya_ss.git
</code></pre><p><img loading=lazy src=images/20240110175054.png></p><p>很快就能完成，接着依次执行</p><pre tabindex=0><code>cd ./kohya_ss
apt update -y &amp;&amp; apt install -y python3-tk
chmod +x ./setup.sh
./setup.sh
</code></pre><p>虽然镜像里带py310，但是似乎还是要装一下python3-tk
之后安装脚本会自动完成，我大概花了5分钟
<img loading=lazy src=images/20240110193312.png>
然后运行启动webui</p><pre tabindex=0><code>HF_ENDPOINT=https://hf-mirror.com ./gui.sh --headless
</code></pre><p><img loading=lazy src=images/20240111114153.png>
点击这个本地的IP即能点开webui了
<code>HF_ENDPOINT=https://hf-mirror.com</code>是为了防止抱脸会更新卡住而用的镜像网站（我确实因为这个卡过）或者见本站另一篇专门说代理的文章：
<a href=https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/>https://winotmk.github.io/240109_Linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/</a></p><h2 id=kohya_ss的dreambooth训练参数>kohya_ss的Dreambooth训练参数<a hidden class=anchor aria-hidden=true href=#kohya_ss的dreambooth训练参数>#</a></h2><h3 id=source-model>source model<a hidden class=anchor aria-hidden=true href=#source-model>#</a></h3><p><img loading=lazy src=images/20240111114635.png>
我这里用自己上传的模型，可以先上传至阿里云oss再挂载进来，所以这里这样选，然后填模型路径就好了</p><h3 id=floders>floders<a hidden class=anchor aria-hidden=true href=#floders>#</a></h3><p>这个tag里比较简单，没什么好说的
Image folder里写上训练集目录，注意写上的目录底下应该是例如10_ABC目录，然后再放图和txt文件，这个10就step的10，和lora训练时候一样</p><h3 id=parameters>parameters<a hidden class=anchor aria-hidden=true href=#parameters>#</a></h3><p><img loading=lazy src=images/20240111115115.png></p><h4 id=basic>basic<a hidden class=anchor aria-hidden=true href=#basic>#</a></h4><p>和lora训练设置大同小异，但是参数要比lora小得多，因为Dreambooth比lora性能消耗要大得多而且非常容易过拟合，图出来一滩浆糊，比如我尝试epoch可能10以内就足够，由于文件比较大Save every N epochs我一般也就3-4，其他参数看个人需求吧</p><h4 id=samples>samples<a hidden class=anchor aria-hidden=true href=#samples>#</a></h4><p>这里能填关键词和每多少轮出个预览图，玩玩用
都准备好了就可以点 <code>start training</code>，但webui不会有任何提示..要看之前启webui的终端
这样就是开始训练了：
<img loading=lazy src=images/20240111121059.png>
不过我第一次成功启动了webui但是点开始训练以后，报过类似这样的错：</p><pre tabindex=0><code>The following directories listed in your path were found to be non-existent: {PosixPath(&#39;/usr/local/nvidia/lib64&#39;), PosixPath(&#39;/usr/local/nvidia/lib&#39;)}
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-11 did not contain [&#39;libcudart.so&#39;, &#39;libcudart.so.11.0&#39;, &#39;libcudart.so.12.0&#39;] as expected! Searching further paths...
  warn(msg)
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;//license-pai.cn-shanghai.data.aliyun.com&#39;), PosixPath(&#39;http&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/cloud-dsw/eas-service&#39;), PosixPath(&#39;aigc-torch113-cu117-ubuntu22.04-v0.2.1&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;http&#39;), PosixPath(&#39;8088/dsw-301739&#39;), PosixPath(&#39;//127.0.0.1&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;Asia/Shanghai&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;tcp&#39;), PosixPath(&#39;443&#39;), PosixPath(&#39;//10.192.0.1&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;https&#39;), PosixPath(&#39;//dsw-cn-shanghai.data.aliyun.com&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;tcp&#39;), PosixPath(&#39;443&#39;), PosixPath(&#39;//10.192.0.1&#39;)}
The following directories listed in your path were found to be non-existent: {PosixPath(&#39;/home/pai/bin/python&#39;)}
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
DEBUG: Possible options found for libcudart.so: {PosixPath(&#39;/usr/local/cuda/lib64/libcudart.so.11.0&#39;)}
CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.0.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: WARNING: Compute capability &lt; 7.5 detected! Only slow 8-bit matmul is supported for your GPU!                     If you run into issues with 8-bit matmul, you can try 4-bit quantization: https://huggingface.co/blog/4bit-transformers-bitsandbytes
  warn(msg)
CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...
libcusparse.so.11: cannot open shared object file: No such file or directory
CUDA SETUP: Something unexpected happened. Please compile from source:
git clone https://github.com/TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=118 make cuda11x_nomatmul
python setup.py install
Traceback (most recent call last):
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 146, in _get_module_details
    return _get_module_details(pkg_main_name, error)
  File &#34;/usr/lib/python3.10/runpy.py&#34;, line 110, in _get_module_details
    __import__(pkg_name)
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py&#34;, line 6, in &lt;module&gt;
    from . import cuda_setup, utils, research
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py&#34;, line 1, in &lt;module&gt;
    from . import nn
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py&#34;, line 1, in &lt;module&gt;
    from .modules import LinearFP8Mixed, LinearFP8Global
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py&#34;, line 8, in &lt;module&gt;
    from bitsandbytes.optim import GlobalOptimManager
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py&#34;, line 6, in &lt;module&gt;
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File &#34;/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py&#34;, line 20, in &lt;module&gt;
    raise RuntimeError(&#39;&#39;&#39;
</code></pre><p>以及如果遇到类似：</p><pre tabindex=0><code>Could not load dynamic library &#39;libcudart.so.11.0&#39;
</code></pre><p>重新装适合的CUDA版本即可解决，如果要装CUDA：</p><h2 id=cuda相关>CUDA相关<a hidden class=anchor aria-hidden=true href=#cuda相关>#</a></h2><h3 id=安装cuda指定版本>安装CUDA指定版本<a hidden class=anchor aria-hidden=true href=#安装cuda指定版本>#</a></h3><p>遇到过cuda版本不匹配的问题，记一下配置过程
cuda下载：https://developer.nvidia.com/cuda-downloads
但是有时候需要特定版本：https://developer.nvidia.com/cuda-toolkit-archive
以11.8为例，系统是ubuntu22.04，所以这样选：
<img loading=lazy src=images/20240111133431.png>
下载安装cuda：</p><pre tabindex=0><code>cd /mnt/workspace
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
</code></pre><p>大约3-4GB左右，运行后需要等一会，会弹出交互界面
<img loading=lazy src=images/20240111135108.png>
这里去掉安装驱动，因为我们已经有驱动了只是想要不同版本的cuda，然后选安装</p><p>ps如果遇到装了多份驱动需要卸一个的情况：
<a href=https://www.jianshu.com/p/54928967e417>https://www.jianshu.com/p/54928967e417</a></p><p>装好以后他会提示：
<img loading=lazy src=images/20240111135653.png>
需要往 <code>LD_LIBRARY_PATH</code> 和 <code>PATH</code> 里添加两条环境变量</p><pre tabindex=0><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64
export PATH=$PATH:/usr/local/cuda-11.8/bin
</code></pre><p>之后我使用</p><pre tabindex=0><code>python -m bitsandbytes
</code></pre><p>如果没有报错应该就是好用的</p><p>ps如果是windows上的wsl：</p><pre tabindex=0><code>export LD_LIBRARY_PATH=/usr/lib/wsl/lib/
</code></pre><h3 id=切换cuda版本>切换cuda版本<a hidden class=anchor aria-hidden=true href=#切换cuda版本>#</a></h3><pre tabindex=0><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.7
export BNB_CUDA_VERSION=117
</code></pre><p>改环境变量可以手动切换版本（当然得已经装了)</p><h3 id=查看cuda版本>查看cuda版本<a hidden class=anchor aria-hidden=true href=#查看cuda版本>#</a></h3><pre tabindex=0><code>nvidia-smi
</code></pre><p>或者可以：
参考：https://blog.csdn.net/Kefenggewu_/article/details/117675079
默认cuda会装在<code>/usr/local</code>,所以查看安装版本可以这样：</p><pre tabindex=0><code>ls -l /usr/local | grep cuda
</code></pre><p>或者据说可以<code>nvcc -V # (V大写)</code></p><p>本节另外的参考：https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md</p><h2 id=链接>链接<a hidden class=anchor aria-hidden=true href=#链接>#</a></h2><p>kohya_ss:
<a href=https://github.com/bmaltais/kohya_ss>https://github.com/bmaltais/kohya_ss</a>
一个封装好的kohya-docker的镜像
<a href=https://github.com/ashleykleynhans/kohya-docker>https://github.com/ashleykleynhans/kohya-docker</a></p><p>dreambooth相关介绍：
<a href=https://huggingface.co/docs/diffusers/training/dreambooth>https://huggingface.co/docs/diffusers/training/dreambooth</a>
<a href=https://github.com/google/dreambooth>https://github.com/google/dreambooth</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:14127/tags/ai/>AI</a></li><li><a href=http://localhost:14127/tags/%E9%98%BF%E9%87%8C%E4%BA%91/>阿里云</a></li><li><a href=http://localhost:14127/tags/stable-diffusion/>Stable Diffusion</a></li><li><a href=http://localhost:14127/tags/linux/>Linux</a></li></ul><nav class=paginav><a class=next href=http://localhost:14127/posts/240109_linux%E4%B8%8A%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BB%A3%E7%90%86%E5%B7%A5%E5%85%B7/><span class=title>Next »</span><br><span>Linux上的命令行代理工具</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on x" href="https://x.com/intent/tweet/?text=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac&amp;url=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f&amp;hashtags=AI%2c%e9%98%bf%e9%87%8c%e4%ba%91%2cstablediffusion%2clinux"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f&amp;title=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac&amp;summary=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac&amp;source=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f&title=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on whatsapp" href="https://api.whatsapp.com/send?text=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac%20-%20http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on telegram" href="https://telegram.me/share/url?text=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac&amp;url=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share StableDiffusion大模型(Dreambooth)云上训练以及安装CODA指定版本 on ycombinator" href="https://news.ycombinator.com/submitlink?t=StableDiffusion%e5%a4%a7%e6%a8%a1%e5%9e%8b%28Dreambooth%29%e4%ba%91%e4%b8%8a%e8%ae%ad%e7%bb%83%e4%bb%a5%e5%8f%8a%e5%ae%89%e8%a3%85CODA%e6%8c%87%e5%ae%9a%e7%89%88%e6%9c%ac&u=http%3a%2f%2flocalhost%3a14127%2fposts%2f240110_sd%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E4%25BA%2591%25E4%25B8%258A%25E8%25AE%25AD%25E7%25BB%2583%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:14127/>ExampleSite</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>